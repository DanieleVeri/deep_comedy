{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "R8FnhxiWY_Y1",
    "outputId": "948d53c3-e0b1-4d73-e526-dadd425092d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-b3198b2150da>\", line 7, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 85, in <module>\n",
      "    from tensorflow.python.ops.standard_ops import *\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\standard_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python import autograph\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 35, in <module>\n",
      "    from tensorflow.python.autograph import operators\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import ConversionOptions\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 69, in <module>\n",
      "    from tensorflow.python.autograph.pyct import anno\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\n",
      "    import gast\n",
      "ModuleNotFoundError: No module named 'gast'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 44, in <module>\n",
      "    from . _api.v2 import autograph\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\autograph\\__init__.py\", line 22, in <module>\n",
      "    from . import experimental\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\autograph\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import Feature\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 69, in <module>\n",
      "    from tensorflow.python.autograph.pyct import anno\n",
      "  File \"C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\n",
      "    import gast\n",
      "ModuleNotFoundError: No module named 'gast'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gast'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5YiWU0daYkT"
   },
   "outputs": [],
   "source": [
    "# Read the Divina Commedia\n",
    "with open(\"C:/Users/damic/Desktop/DivinaCommedia.txt\", 'r') as file:\n",
    "    divina_commedia = file.read()\n",
    "\n",
    "# Replace rare characters\n",
    "divina_commedia = divina_commedia.replace(\"ä\", \"a\")\n",
    "divina_commedia = divina_commedia.replace(\"é\", \"è\")\n",
    "divina_commedia = divina_commedia.replace(\"ë\", \"è\")\n",
    "divina_commedia = divina_commedia.replace(\"Ë\", \"E\")\n",
    "divina_commedia = divina_commedia.replace(\"ï\", \"i\")\n",
    "divina_commedia = divina_commedia.replace(\"Ï\", \"I\")\n",
    "divina_commedia = divina_commedia.replace(\"ó\", \"ò\")\n",
    "divina_commedia = divina_commedia.replace(\"ö\", \"o\")\n",
    "divina_commedia = divina_commedia.replace(\"ü\", \"u\")\n",
    "\n",
    "divina_commedia = divina_commedia.replace(\"(\", \"-\")\n",
    "divina_commedia = divina_commedia.replace(\")\", \"-\")\n",
    "divina_commedia = divina_commedia.replace(\"[\", \"\")\n",
    "divina_commedia = divina_commedia.replace(\"]\", \"\")\n",
    "\n",
    "divina_commedia = re.sub(r'[0-9]+', '', divina_commedia)\n",
    "divina_commedia = divina_commedia.replace(\" \\n\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ILphRXIXaYrP",
    "outputId": "108f777a-2f35-4b90-a086-42b326022d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551704\n"
     ]
    }
   ],
   "source": [
    "# Check lenght of text\n",
    "print(len(divina_commedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwvjeLGWAVE4"
   },
   "outputs": [],
   "source": [
    "# Store unique characters into a dict with numerical encoding\n",
    "unique_chars = list(set(divina_commedia))\n",
    "unique_chars.sort()  # to make sure you get the same encoding at each run\n",
    "\n",
    "# Store them in a dict, associated with a numerical index\n",
    "char2idx = { char[1]: char[0] for char in enumerate(unique_chars) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tkXOJ3LGAVCF",
    "outputId": "b020a397-eafb-4b39-9f76-1d361abd3fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(char2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2sieJxDhAU_V",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "79310734-7f0f-4e6c-c773-258a5358ed9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " \"'\": 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " ':': 8,\n",
       " ';': 9,\n",
       " '?': 10,\n",
       " 'A': 11,\n",
       " 'B': 12,\n",
       " 'C': 13,\n",
       " 'D': 14,\n",
       " 'E': 15,\n",
       " 'F': 16,\n",
       " 'G': 17,\n",
       " 'H': 18,\n",
       " 'I': 19,\n",
       " 'L': 20,\n",
       " 'M': 21,\n",
       " 'N': 22,\n",
       " 'O': 23,\n",
       " 'P': 24,\n",
       " 'Q': 25,\n",
       " 'R': 26,\n",
       " 'S': 27,\n",
       " 'T': 28,\n",
       " 'U': 29,\n",
       " 'V': 30,\n",
       " 'X': 31,\n",
       " 'Z': 32,\n",
       " 'a': 33,\n",
       " 'b': 34,\n",
       " 'c': 35,\n",
       " 'd': 36,\n",
       " 'e': 37,\n",
       " 'f': 38,\n",
       " 'g': 39,\n",
       " 'h': 40,\n",
       " 'i': 41,\n",
       " 'j': 42,\n",
       " 'l': 43,\n",
       " 'm': 44,\n",
       " 'n': 45,\n",
       " 'o': 46,\n",
       " 'p': 47,\n",
       " 'q': 48,\n",
       " 'r': 49,\n",
       " 's': 50,\n",
       " 't': 51,\n",
       " 'u': 52,\n",
       " 'v': 53,\n",
       " 'x': 54,\n",
       " 'y': 55,\n",
       " 'z': 56,\n",
       " 'È': 57,\n",
       " 'à': 58,\n",
       " 'è': 59,\n",
       " 'ì': 60,\n",
       " 'ò': 61,\n",
       " 'ù': 62}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vk_BqFK4AU9H"
   },
   "outputs": [],
   "source": [
    "def numerical_encoding(text, char_dict):\n",
    "    \"\"\" Text to list of chars, to np.array of numerical idx \"\"\"\n",
    "    chars_list = [ char for char in text ]\n",
    "    chars_list = [ char_dict[char] for char in chars_list ]\n",
    "    chars_list = np.array(chars_list)\n",
    "    return chars_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "r7JpYN9LAU7U",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "79f714c0-a0a6-495f-e900-c39d3b329b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nel mezzo del cammin di nostra vita\n",
      "\n",
      "becomes:\n",
      "[22 37 43  1 44 37 56 56 46  1 36 37 43  1 35 33 44 44 41 45  1 36 41  1\n",
      " 45 46 50 51 49 33  1 53 41 51 33]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first line will look like\n",
    "print(\"{}\".format(divina_commedia[276:311]))\n",
    "print(\"\\nbecomes:\")\n",
    "print(numerical_encoding(divina_commedia[276:311], char2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWcZzOJdG6X9"
   },
   "outputs": [],
   "source": [
    "# Apply it on the whole Comedy\n",
    "encoded_text = numerical_encoding(divina_commedia, char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t41gYByxAU4B"
   },
   "outputs": [],
   "source": [
    "def get_text_matrix(sequence, len_input):\n",
    "    \n",
    "    # create empty matrix\n",
    "    X = np.empty((len(sequence)-len_input, len_input))\n",
    "    \n",
    "    # fill each row/time window from input sequence\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i,:] = sequence[i : i+len_input]\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5eazAAQiAk0i"
   },
   "outputs": [],
   "source": [
    "text_matrix = get_text_matrix(encoded_text, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KonviQjQAk40",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3d20f758-3088-4645-9aa3-3ee3d4f40823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551604, 100)\n"
     ]
    }
   ],
   "source": [
    "print(text_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "BaVngDG7AkyU",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "730a7be7-daf2-4eb7-f536-9e281cbc662f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100th train sequence:\n",
      "\n",
      "[45. 37.  1. 37.  1. 47. 52. 45. 41. 44. 37. 45. 51. 41.  1. 36. 37.  4.\n",
      "  1. 53. 41. 56. 41.  1. 37.  1. 36. 37.  4.  1. 44. 37. 49. 41. 51. 41.\n",
      "  1. 37.  1. 47. 49. 37. 44. 41.  1. 36. 37.  1. 43. 37.  1. 53. 41. 49.\n",
      " 51. 62.  7.  1. 13. 46. 44. 41. 45. 35. 41. 33.  1. 41. 43.  1. 35. 33.\n",
      " 45. 51. 46.  1. 47. 49. 41. 44. 46.  1. 36. 37.  1. 43. 33.  1. 47. 49.\n",
      " 41. 44. 33.  1. 47. 33. 49. 51. 37.  1.]\n",
      "\n",
      "\n",
      "100th target sequence:\n",
      "\n",
      "[37.  1. 37.  1. 47. 52. 45. 41. 44. 37. 45. 51. 41.  1. 36. 37.  4.  1.\n",
      " 53. 41. 56. 41.  1. 37.  1. 36. 37.  4.  1. 44. 37. 49. 41. 51. 41.  1.\n",
      " 37.  1. 47. 49. 37. 44. 41.  1. 36. 37.  1. 43. 37.  1. 53. 41. 49. 51.\n",
      " 62.  7.  1. 13. 46. 44. 41. 45. 35. 41. 33.  1. 41. 43.  1. 35. 33. 45.\n",
      " 51. 46.  1. 47. 49. 41. 44. 46.  1. 36. 37.  1. 43. 33.  1. 47. 49. 41.\n",
      " 44. 33.  1. 47. 33. 49. 51. 37.  1. 43.]\n"
     ]
    }
   ],
   "source": [
    "print(\"100th train sequence:\\n\")\n",
    "print(text_matrix[ 100, : ])\n",
    "print(\"\\n\\n100th target sequence:\\n\")\n",
    "print(text_matrix[ 101, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFZfbimYAkvk"
   },
   "outputs": [],
   "source": [
    "# size of vocabulary\n",
    "vocab_size = len(char2idx)\n",
    "\n",
    "# size of mini batches during training\n",
    "batch_size = 100\n",
    "\n",
    "# size of training subset at each epoch\n",
    "subset_size = batch_size * 100\n",
    "\n",
    "# vector size of char embeddings\n",
    "embedding_size = 250\n",
    "\n",
    "len_input = 1000   # 200\n",
    "\n",
    "hidden_size = 250  # for Dense() layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1JqO7rhAktC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.activations import elu, relu, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mKysyBfpAtUS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6d987cb1-40ee-4896-8b41-d52ae0cf70a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\damic\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (100, None, 250)          15750     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (100, None, 1000)         5004000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, None, 250)          250250    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, None, 63)           15813     \n",
      "=================================================================\n",
      "Total params: 5,285,813\n",
      "Trainable params: 5,285,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN = Sequential([\n",
    "    Embedding(vocab_size, embedding_size,\n",
    "              batch_input_shape=(batch_size, None)),\n",
    "    \n",
    "    LSTM(len_input, return_sequences = True),\n",
    "    \n",
    "    Dense(hidden_size, activation = relu), \n",
    "    \n",
    "    Dense(vocab_size)\n",
    "])\n",
    "\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9Tldq4qAtXr"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUgGeC5ZAtbb"
   },
   "outputs": [],
   "source": [
    "# This is an Autograph function\n",
    "# its decorator makes it a TF op - i.e. much faster\n",
    "@tf.function\n",
    "def train_on_batch(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                y, RNN(x), from_logits = True))\n",
    "    gradients = tape.gradient(current_loss, RNN.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, RNN.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8-x5RxKrAtnR",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "526b30d3-af50-4cc4-8356-7c22ea15c7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-382abd0a8ab5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     print(\"{}.  \\t  Loss: {}  \\t  Time: {}ss\".format(\n\u001b[1;32m---> 20\u001b[1;33m         epoch+1, current_loss.numpy(), round(time.time()-start, 2)))\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    print(epoch)\n",
    "    # Take subsets of train and target\n",
    "    sample = np.random.randint(0, text_matrix.shape[0]-1, subset_size)\n",
    "    sample_train = text_matrix[ sample , : ]\n",
    "    sample_target = text_matrix[ sample+1 , : ]\n",
    "    \n",
    "    for iteration in range(sample_train.shape[0] // batch_size):\n",
    "        take = iteration * batch_size\n",
    "        x = sample_train[ take:take+batch_size , : ]\n",
    "        y = sample_target[ take:take+batch_size , : ]\n",
    "\n",
    "        current_loss = train_on_batch(x, y)\n",
    "        loss_history.append(current_loss)\n",
    "    \n",
    "    print(\"{}.  \\t  Loss: {}  \\t  Time: {}ss\".format(\n",
    "        epoch+1, current_loss.numpy(), round(time.time()-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "R6uAhmV2Atth",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "407b71d5-18bf-49e9-ec14-1ecf8def79b4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLiKSJBToIiJJQoEuIpIk/g/NFPg3qgiV4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCsDapUTBBrE"
   },
   "outputs": [],
   "source": [
    "RNN.save(current_path + \"models/text_generator_RNN_00.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "69aV7FGVAtxY",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "87c106a7-f0cf-4bf4-8507-13551f88d290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 250)            15750     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1000)           5004000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 250)            250250    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 63)             15813     \n",
      "=================================================================\n",
      "Total params: 5,285,813\n",
      "Trainable params: 5,285,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential([\n",
    "    Embedding(vocab_size, embedding_size,\n",
    "              batch_input_shape=(1, None)),\n",
    "    \n",
    "    LSTM(len_input, return_sequences = True, stateful=True),\n",
    "    \n",
    "    Dense(hidden_size, activation = relu), \n",
    "    \n",
    "    Dense(vocab_size)\n",
    "])\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whB1azhVAtrp",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import trained weights from RNN to generator\n",
    "generator.set_weights(RNN.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE2hYSqAAtkn",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(start_string, num_generate = 1000, temperature = 1.0):\n",
    "    \n",
    "    # Vectorize input string\n",
    "    input_eval = [char2idx[s] for s in start_string]  \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = [] # List to append predicted chars \n",
    "    \n",
    "    idx2char = { v: k for k, v in char2idx.items() }  # invert char-index mapping\n",
    "    \n",
    "    generator.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = generator(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # sample next char based on distribution and temperature\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(text_generated))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOEZEYhXCzaOY4YC7IIdsvh",
   "collapsed_sections": [],
   "name": "RNN_text_generator_00.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
