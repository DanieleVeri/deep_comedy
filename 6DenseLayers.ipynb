{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Training.ipynb","provenance":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JNI_CLbCVJqo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595866118143,"user_tz":-120,"elapsed":26052,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}},"outputId":"4c480aab-6eaa-4283-ff3b-a1e7e664a082"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XCYfaVGeU774","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948559,"user_tz":-120,"elapsed":56150,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["from pathlib import Path\n","import os\n","import keras\n","os.chdir('/content/drive/My Drive/haikurnn-master/haikurnn-master/notebooks/models/v1')\n","tf_session = tf.Session()\n","from keras import backend as K\n","K.set_session(tf_session)\n","import math\n","from keras.callbacks import ModelCheckpoint,  CSVLogger\n","from keras.layers import Add, Dense, Input, LSTM\n","from keras.models import Model\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import np_utils\n","import requests\n","import numpy as np\n","import pandas as pd\n","from sklearn.externals import joblib"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JaeVQmCAU779","colab_type":"text"},"source":["# Load Input"]},{"cell_type":"code","metadata":{"id":"72OQufHqU77-","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948561,"user_tz":-120,"elapsed":56142,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["# Settings\n","\n","# Percent of samples to use for training, might be necessary if you're running out of memory\n","sample_size = 1\n","\n","# The latent dimension of the LSTM\n","latent_dim = 4096\n","\n","# Number of epochs to train for\n","epochs = 40\n","\n","name = 'test'\n","output_dir = Path('output_%s' % name)\n","output_dir.mkdir()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0DFCwgua_8u","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948561,"user_tz":-120,"elapsed":56135,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["f1 = open(\"first.txt\",\"r\")\n","f2 = open(\"second.txt\",\"r\")\n","f3 = open(\"third.txt\",\"r\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVwEQT0hdmic","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948562,"user_tz":-120,"elapsed":56128,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["first = f1.read().split(sep='\\n')\n","second = f2.read().split(sep='\\n')\n","third = f3.read().split(sep='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uu60ZWhAfuDf","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948563,"user_tz":-120,"elapsed":56122,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["for x in first:\n","  if len(x) < 2:\n","    first.remove(x)\n","for x in second:\n","  if len(x) < 2:\n","    second.remove(x)\n","for x in third:\n","  if len(x) < 2:\n","    third.remove(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHHZ-gejgc3T","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948564,"user_tz":-120,"elapsed":56115,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["print(len(first), len(second), len(third))\n","first = first[:4744]\n","print(len(first), len(second), len(third))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bKrvRAafVCq","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948565,"user_tz":-120,"elapsed":56102,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["df = pd.DataFrame()\n","df['0'] = first[0::2]\n","df['1'] = second[0::2]\n","df['2'] = third[0::2]\n","df['3'] = first[1::2]\n","df['4'] = second[1::2]\n","df['5'] = third[1::2]\n","df['0_syllables'] = [11 for x in range(2372)]\n","df['1_syllables'] = [11 for x in range(2372)]\n","df['2_syllables'] = [11 for x in range(2372)]\n","df['3_syllables'] = [11 for x in range(2372)]\n","df['4_syllables'] = [11 for x in range(2372)]\n","df['5_syllables'] = [11 for x in range(2372)]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mckVDu6ZU78J","colab_type":"text"},"source":["# Format Input for Training"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"UlnJ6ipGU78O","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948566,"user_tz":-120,"elapsed":56092,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["# Drop samples that are longer that the 99th percentile of length\n","\n","max_line_length = int(max([df['%s' % i].str.len().quantile(.99999) for i in range(6)]))\n","df = df[\n","    (df['0'].str.len() <= max_line_length) & \n","    (df['1'].str.len() <= max_line_length) & \n","    (df['2'].str.len() <= max_line_length) &\n","    (df['3'].str.len() <= max_line_length) & \n","    (df['4'].str.len() <= max_line_length) & \n","    (df['5'].str.len() <= max_line_length)\n","].copy()\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MGD8cfvU78S","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948567,"user_tz":-120,"elapsed":56082,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["# Pad the lines to the max line length with new lines\n","for i in range(6):\n","    # For input, duplicate the first character\n","    df['%s_in' % i] = (df[str(i)].str[0] + df[str(i)]).str.pad(max_line_length+2, 'right', '\\n')\n","    \n","    if i == 5: # If it's the last line\n","        df['%s_out' % i] = df[str(i)].str.pad(max_line_length+2, 'right', '\\n')\n","    else: \n","        # If it's the first or second line, add the first character of the next line to the end of this line.\n","        # This helps with training so that the next RNN has a better chance of getting the first character right.\n","        df['%s_out' % i] = (df[str(i)] + '\\n' + df[str(i+1)].str[0]).str.pad(max_line_length+2, 'right', '\\n')\n","    \n","max_line_length += 2\n","\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"saTxe6d8U78X","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948568,"user_tz":-120,"elapsed":56076,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["inputs = df[['0_in', '1_in', '2_in', '3_in', '4_in', '5_in']].values\n","\n","tokenizer = Tokenizer(filters='', char_level=True)\n","tokenizer.fit_on_texts(inputs.flatten())\n","n_tokens = len(tokenizer.word_counts) + 1\n","\n","# X is the input for each line in sequences of one-hot-encoded values\n","X = np_utils.to_categorical([\n","    tokenizer.texts_to_sequences(inputs[:,i]) for i in range(6)\n","], num_classes=n_tokens)\n","\n","outputs = df[['0_out', '1_out', '2_out', '3_out', '4_out', '5_out']].values\n","\n","# Y is the output for each line in sequences of one-hot-encoded values\n","Y = np_utils.to_categorical([\n","    tokenizer.texts_to_sequences(outputs[:,i]) for i in range(6)\n","], num_classes=n_tokens)\n","\n","# X_syllables is the count of syllables for each line\n","X_syllables = df[['0_syllables', '1_syllables', '2_syllables', '3_syllables', '4_syllables', '5_syllables']].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WJscJRsU78b","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948569,"user_tz":-120,"elapsed":56068,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["joblib.dump([latent_dim, n_tokens, max_line_length, tokenizer], str(output_dir / 'metadata.pkl'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3mSx66cMU78e","colab_type":"text"},"source":["# Training Model"]},{"cell_type":"code","metadata":{"id":"OnkCcwCBVbvD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948570,"user_tz":-120,"elapsed":56059,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["class TrainingLine:\n","    def __init__(self, name, previous_line, lstm, lstm1, n_tokens):\n","        self.char_input = Input(shape=(None, n_tokens), name='char_input_%s' % name)\n","\n","        self.syllable_input = Input(shape=(1,), name='syllable_input_%s' % name)\n","        self.syllable_dense = Dense(lstm.units, activation='relu', name='syllable_dense_%s' % name)\n","        self.syllable_dense_output = self.syllable_dense(self.syllable_input)\n","\n","        #self.lstm = LSTM(latent_dim, return_state=True, return_sequences=True, name='lstm_%s' % name)\n","\n","        if previous_line:\n","            initial_state = [\n","                Add(name='add_h_%s' % name)([\n","                    previous_line.lstm_h,\n","                    self.syllable_dense_output\n","                ]),\n","                Add(name='add_c_%s' % name)([\n","                    previous_line.lstm_c,\n","                    self.syllable_dense_output\n","                ])\n","            ]\n","        else:\n","            initial_state = [self.syllable_dense_output, self.syllable_dense_output]\n","\n","        self.lstm_out, self.lstm_h, self.lstm_c = lstm(self.char_input, initial_state=initial_state)\n","\n","        self.output_dense = Dense(n_tokens, activation='softmax', name='output_%s' % name)\n","        self.output = self.output_dense(self.lstm_out)\n","\n","def create_training_model(latent_dim, n_tokens):\n","    lstm = LSTM(latent_dim, return_state=True, return_sequences=True, name='lstm')\n","    lstm1 = LSTM(latent_dim, return_state=True, return_sequences=True, name='lstm')\n","    lines = []\n","    inputs = []\n","    outputs = []\n","\n","    for i in range(6):\n","        previous_line = lines[-1] if lines else None\n","        lines.append(TrainingLine('line_%s' % i, previous_line, lstm, lstm1, n_tokens))\n","        inputs += [lines[-1].char_input, lines[-1].syllable_input]\n","        outputs.append(lines[-1].output)\n","\n","    training_model = Model(inputs, outputs)\n","    training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","\n","    return training_model, lstm, lines, inputs, outputs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nIsXFtc5U78f","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948570,"user_tz":-120,"elapsed":56049,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["training_model, lstm, lines, inputs, outputs = create_training_model(latent_dim, n_tokens)\n","print(training_model.summary())\n","filepath = str(output_dir / (\"%s-{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\" % latent_dim))\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","\n","csv_logger = CSVLogger(str(output_dir / 'training_log.csv'), append=True, separator=',')\n","\n","callbacks_list = [checkpoint, csv_logger]\n","\n","training_model.fit([\n","    X[0], X_syllables[:,0], \n","    X[1], X_syllables[:,1], \n","    X[2], X_syllables[:,2],\n","    X[3], X_syllables[:,3],\n","    X[4], X_syllables[:,4],\n","    X[5], X_syllables[:,5]\n","], [Y[0], Y[1], Y[2], Y[3], Y[4], Y[5]], batch_size=16, epochs=epochs, validation_split=.1, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YRhPskjPU78i","colab_type":"text"},"source":["# Test Model"]},{"cell_type":"code","metadata":{"id":"QGBBkPQaPcvb","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948571,"user_tz":-120,"elapsed":56040,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["class GeneratorLine:\n","    def __init__(self, name, training_line, lstm, n_tokens):\n","        self.char_input = Input(shape=(None, n_tokens), name='char_input_%s' % name)\n","\n","        self.syllable_input = Input(shape=(1,), name='syllable_input_%s' % name)\n","        self.syllable_dense = Dense(lstm.units, activation='relu', name='syllable_dense_%s' % name)\n","        self.syllable_dense_output = self.syllable_dense(self.syllable_input)\n","\n","        self.h_input = Input(shape=(lstm.units,), name='h_input_%s' % name)\n","        self.c_input = Input(shape=(lstm.units,), name='c_input_%s' % name)\n","        initial_state = [self.h_input, self.c_input]\n","\n","        self.lstm = lstm\n","\n","        self.lstm_out, self.lstm_h, self.lstm_c = self.lstm(self.char_input, initial_state=initial_state)\n","\n","        self.output_dense = Dense(n_tokens, activation='softmax', name='output_%s' % name)\n","        self.output = self.output_dense(self.lstm_out)\n","\n","        self.syllable_dense.set_weights(training_line.syllable_dense.get_weights())\n","        self.output_dense.set_weights(training_line.output_dense.get_weights())\n","\n","def sample(preds, temperature=1):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","class Generator:\n","    def __init__(self, lstm, lines, tf_session, tokenizer, n_tokens, max_line_length):\n","        self.tf_session = tf_session\n","        self.tokenizer = tokenizer\n","        self.n_tokens = n_tokens\n","        self.max_line_length = max_line_length\n","\n","        self.lstm = LSTM(\n","            lstm.units, return_state=True, return_sequences=True,\n","            name='generator_lstm'\n","        )\n","        self.lstm1 = LSTM(\n","            lstm.units, return_state=True, return_sequences=True,\n","            name='generator_lstm'\n","        )\n","        self.lines = [\n","            GeneratorLine(\n","                'generator_line_%s' % i,\n","                lines[i], self.lstm, self.n_tokens\n","            ) for i in range(6)\n","        ]\n","        self.lstm.set_weights(lstm.get_weights())\n","        self.lstm1.set_weights(lstm1.get_weights())\n","\n","    def generate(self, syllables=[11, 11, 11, 11, 11, 11], temperature=1, first_char=None):\n","        output = []\n","        h = None\n","        c = None\n","\n","        if first_char is None:\n","            first_char = chr(int(np.random.randint(ord('a'), ord('z')+1)))\n","\n","        next_char = self.tokenizer.texts_to_sequences(first_char)[0][0]\n","\n","        for i in range(6):\n","            line = self.lines[i]\n","            s = self.tf_session.run(\n","                line.syllable_dense_output,\n","                feed_dict={\n","                    line.syllable_input: [[syllables[i]]]\n","                }\n","            )\n","\n","            if h is None:\n","                h = s\n","                c = s\n","            else:\n","                h = h + s\n","                c = c + s\n","\n","            line_output = [next_char]\n","            tokens = self.n_tokens\n","            end = False\n","            next_char = None\n","            for i in range(self.max_line_length):\n","                char, h, c = self.tf_session.run(\n","                    [line.output, line.lstm_h, line.lstm_c],\n","                    feed_dict={\n","                        line.char_input: [[\n","                            np_utils.to_categorical(\n","                                line_output[-1],\n","                                num_classes=self.n_tokens\n","                            )\n","                        ]],\n","                        line.h_input: h,\n","                        line.c_input: c\n","                    }\n","                )\n","\n","                char = sample(char[0,0], temperature)\n","                if char == 1 and not end:\n","                    end = True\n","                if char != 1 and end:\n","                    next_char = char\n","                    char = 1\n","                line_output.append(char)\n","            \n","            cleaned_text = self.tokenizer.sequences_to_texts([\n","                line_output\n","            ])[0].strip()[1:].replace(\n","                '   ', '\\n'\n","            ).replace(' ', '').replace('\\n', ' ')\n","\n","            print(cleaned_text)\n","            output.append(cleaned_text)\n","        print('\\n')\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2pnP7ymtU78o","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948571,"user_tz":-120,"elapsed":56033,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":["for boh in range(30):\n","  generator = Generator(lstm, lines, tf_session, tokenizer, n_tokens, max_line_length)\n","  generator.generate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5eixLLynDWN","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1595865948572,"user_tz":-120,"elapsed":56027,"user":{"displayName":"Giacomo","photoUrl":"https://lh6.googleusercontent.com/-_yNWKXs4tL8/AAAAAAAAAAI/AAAAAAAAv5Y/ThWC96YwxpY/s64/photo.jpg","userId":"11330407691056598140"}}},"source":[" "],"execution_count":null,"outputs":[]}]}